%% ğŸ”¹ 1. ì˜ˆì¸¡ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
fprintf("[INFO] ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n");
result = readtable("evaluation_result_20250706_132042.csv");  % â† ìˆ˜ì •

%% ğŸ”¹ 2. ì •ë‹µê°’ ë¶ˆëŸ¬ì˜¤ê¸°
fprintf("[INFO] CFIS ì •ë‹µ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...\n");
truth = readtable("cfis_test_label.csv");

if ismember("Pspread", truth.Properties.VariableNames)
    Y_true = truth.Pspread;
else
    error("âŒ cfis_test_label.csvì— Pspread ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.");
end

Y_pred = result.pSpread_pred;

%% ğŸ”¹ 3. ì„±ëŠ¥ í‰ê°€
fprintf("[INFO] ì„±ëŠ¥ í‰ê°€ ì¤‘ (RMSE, MAE)...\n");
rmse = sqrt(mean((Y_true - Y_pred).^2));
mae = mean(abs(Y_true - Y_pred));

fprintf("\n[RESULT] ğŸ“‰ RMSE: %.4f\n", rmse);
fprintf("[RESULT] ğŸ“‰ MAE : %.4f\n", mae);

%% ğŸ”¹ 4. ê²°ê³¼ í…Œì´ë¸” êµ¬ì„± ë° ì €ì¥
result.Pspread_true = Y_true;
result.abs_error = abs(Y_true - Y_pred);

output_filename = ['evaluation_result_', datestr(now, 'yyyymmdd_HHMMSS'), '.csv'];
writetable(result, output_filename);
fprintf("[ì™„ë£Œ] í‰ê°€ ê²°ê³¼ ì €ì¥ë¨ â†’ %s\n", output_filename);

%% ğŸ”¹ 5. ì‹œê°í™” - ì˜ˆì¸¡ ì§€ë„
figure;
scatter(result.center_lon, result.center_lat, 20, result.pSpread_pred, 'filled');
colormap(jet); colorbar; caxis([0 1]);
xlabel('Longitude'); ylabel('Latitude');
title('ğŸ”¥ ì˜ˆì¸¡ í™•ì‚° í™•ë¥  ì§€ë„ (Gradient Boosting)');
grid on;

%% ğŸ”¹ 6. ì‹œê°í™” - ì‹¤ì œ ì§€ë„
figure;
scatter(result.center_lon, result.center_lat, 20, result.Pspread_true, 'filled');
colormap(jet); colorbar; caxis([0 1]);
xlabel('Longitude'); ylabel('Latitude');
title('ğŸ“ ì‹¤ì œ í™•ì‚° í™•ë¥  ì§€ë„ (CFIS)');
grid on;

%% ğŸ”¹ 7. ì‹œê°í™” - ì˜¤ì°¨ ì§€ë„
figure;
scatter(result.center_lon, result.center_lat, 20, result.abs_error, 'filled');
colormap(parula); colorbar;
xlabel('Longitude'); ylabel('Latitude');
title('ğŸ§­ ì˜ˆì¸¡ ì˜¤ì°¨ ì§€ë„ (ì ˆëŒ€ ì˜¤ì°¨)');
grid on;

%% ğŸ”¹ 8. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° + í”¼ì²˜ ì¤‘ìš”ë„
fprintf("[INFO] í•™ìŠµëœ ëª¨ë¸ ë¡œë”© ì¤‘...\n");
load("gradient_boosting_pspread_model_300trees_20250706_131211.mat");  % â† íŒŒì¼ëª… ìˆ˜ì •

fprintf("[INFO] í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ì¤‘...\n");
importance = predictorImportance(model);
varNames = model.PredictorNames;

[sortedImp, idx] = sort(importance, 'descend');
fprintf("\nğŸ” Top 3 ì¤‘ìš” í”¼ì²˜ (Gradient Boosting ê¸°ì¤€):\n");
for i = 1:3
    fprintf("%d. %s (Importance: %.4f)\n", i, varNames{idx(i)}, sortedImp(i));
end

% ì¤‘ìš”ë„ ì‹œê°í™”
figure;
bar(importance(idx));
xticklabels(varNames(idx));
xtickangle(45);
ylabel('Importance Score');
title('ğŸ“Š Feature Importance (Gradient Boosting)');
grid on;

%% ğŸ”¹ 9. íŠ¸ë¦¬ ìˆ˜ì— ë”°ë¥¸ í•™ìŠµ ì˜¤ì°¨ ê·¸ë˜í”„
fprintf("[INFO] íŠ¸ë¦¬ ìˆ˜ì— ë”°ë¥¸ í•™ìŠµ ì˜¤ì°¨ ê³„ì‚° ì¤‘...\n");
nTrees = model.NumTrained;
resubErrors = zeros(nTrees, 1);

for t = 1:nTrees
    resubErrors(t) = resubLoss(model, 'Mode', 'Ensemble', 'Learners', 1:t);
end

figure;
plot(1:nTrees, resubErrors, 'LineWidth', 2);
xlabel('Number of Trees');
ylabel('Resubstitution Loss');
title('ğŸ“‰ Gradient Boosting Learning Curve');
grid on;
